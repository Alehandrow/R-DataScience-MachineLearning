{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping mit R\n",
    "\n",
    "*Hinweis: Um diese Lektion vollständig zu verstehen sind Kenntnisse von HTML und CSS notwendig. Außerdem solltest du den Pipe Operator in R (%>%) kennen. Komme ggf. zu dieser Lektion zurück, sobald du das Material kennst.*\n",
    "\n",
    "Web Scraping ist generell immer sehr vom einzelnen Use Case abhängig. Das liegt daran, dass jede Webseite indiviudell aufgebaut und gestalltet ist, Updates durchgeführt werden und sich Dinge verändern. Um Web Scraping mit R komplett zu verstehen ist ein Grundwissen von HTML und CSS notwendig. Dadurch können wir verstehen, was wir uns von der Webseite holen wollen.\n",
    "\n",
    "Falls ihr HTML und CSS nicht kennt, könnt ihr ein Auto-Web-Scrape Tool wie [import.io](https://www.import.io/) nutzen.\n",
    "\n",
    "## rvest library\n",
    "\n",
    "Hier findet ihr ein Beispiel der nutzung von `rvest`. Der beste Weg zum Lernen ist die Nutzung der bereitgestellten Demos, auf die man wie folgt zugreift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo(package='rvest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sofern du mit HTML und CSS vertraut bist ist `rvest` eine sehr nützliche Library.  Wir gehen jetzt ein Beispiel aus dem R Studio durch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘BH’, ‘xml2’, ‘selectr’\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/l_/ph09zg211515zffvzrp3bb680000gn/T//RtmpNsECYb/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# Will also install dependencies\n",
    "install.packages('rvest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellen wir uns vor, wir würden Informationen über den Lego Film von IMDB auslesen wollen. Wir beginnen dazu mit dem Download der HTML-Datei mit `html()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(rvest)\n",
    "lego_film <- read_html(\"http://www.imdb.com/title/tt1490017/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um im nächsten Schritt die Bewertung zu erhalten nutzen wir das \"Selector Gadget\". Dadurch finden wir heraus welcher CSS-Selektor mit den Daten übereinstimmt, die wir möchten. Falls ihr das Gadget nicht kennt, dann lest euch [\"SelectorGadget\"](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html) durch – es ist der einfachste Weg, um zu bestimmen, welcher Selektor die Daten extrahiert, die uns interesieren. Wir nutzen `html_node()` um den ersten Node zu finden, der mit dem Selektor übereinstimmt. Dann extrahieren wir seinen Inhalt mit `html_text()` und konvertiren den Inhalt mit `as.numeric()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lego_film %>% \n",
    "  html_node(\"strong span\") %>%\n",
    "  html_text() %>%\n",
    "  as.numeric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nutzen einen ähnlichen Prozess um den Cast zu extrahieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lego_film %>%\n",
    "  html_nodes(\"#titleCast .itemprop span\") %>%\n",
    "  html_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Titel und Autoren von neuen Posts sind in einer dritten Tabelle auf der Seite gespeichert. Wir können `html_nodes()` und [[ ]] nutzen, um sie zu finden. Anschließend wandeln wir es in einen Data Frame um, indem wir `html_table()` nutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lego_film %>%\n",
    "  html_nodes(\"table\") %>%\n",
    "  .[[3]] %>%\n",
    "  html_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soweit so gut! Hoffentlich konntet ihr einen ersten Eindruck des Web Scrapings mit R gewinnen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
